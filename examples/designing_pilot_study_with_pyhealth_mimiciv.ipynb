{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPpYREkXYssmJ0QJiSDYfy5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["UIUC: CS598:DLH Example/Use Case PR Submission From:\n","\n","Swaroop Potdar netid (spotd), Jake Cumberland netid (jakepc3)"],"metadata":{"id":"maRv0uFcH66W"}},{"cell_type":"markdown","source":["# Designing Pilot/Proof of Concept Study With PyHealth and MIMIC-IV"],"metadata":{"id":"AB-AFcPh-z3n"}},{"cell_type":"markdown","source":["# Objective:\n","Considering the privacy concerns and paucity of available data, the goal of this workflow is to match the MIMIC-IV Waveform Database (WaveDB) with MIMIC-IV Clinical Ground truth data to enable useful analysis. Specifically, by linking patient diagnosis information with waveform data, we can create datasets that can be used for machine learning tasks. These datasets make for an ideal pilot or proof of concept study, where we can asses the validity of our hypothesis before collecting more and diverse data on a larger scale.\n","\n","For example, we can identify which patients are positive for conditions like Atrial Fibrillation, and then match them with their corresponding waveform records and choose control subjects who are negative for the target condition but still have waveform records.\n","\n","\n","**The workflow proceeds through the following steps:**\n","\n","1.  Load MIMIC-IV clinical data (DIAGNOSES_ICD table) as ground truth.\n","\n","2.  Load MIMIC-IV waveform database records (RECORDS file).\n","\n","3.  Extract diagnosis names from the ICD-9 and ICD-10 datasets.\n","\n","4.  Merge clinical diagnosis data with waveform records to filter patients with specific diagnoses.\n","\n","5.  Perform the final filtering by diagnosis name or ICD code to generate the final dataset for machine learning or other analysis.\n","\n","6.  Download only the necessary waveform files"],"metadata":{"id":"GdkcFTA0q6aB"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XX4qcnsyI7fX","executionInfo":{"status":"ok","timestamp":1746634393925,"user_tz":240,"elapsed":14729,"user":{"displayName":"Swaroop Potdar","userId":"00045263918087141429"}},"outputId":"6e2a85cd-6bac-48b0-9ee9-36577155edcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### Clone PyHealth and Install dependencies"],"metadata":{"id":"sSsQVsjGsPxf"}},{"cell_type":"code","source":["# This is done in Colab, if executing locally adjust the path to match your local setup.\n","%cd /content/drive/MyDrive/\n","!git clone https://github.com/sunlabuiuc/PyHealth.git\n","%cd /content/drive/MyDrive/PyHealth/\n","!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEPexI5Fhdy5","executionInfo":{"status":"ok","timestamp":1746647891834,"user_tz":240,"elapsed":46,"user":{"displayName":"Swaroop Potdar","userId":"00045263918087141429"}},"outputId":"3b15f93d-cc38-4bfd-ec62-15fe8d7917c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"markdown","source":["### Load MIMIC-IV Clinical Data\n","\n","The MIMIC-IV clinical dataset is loaded, specifically focusing on the DIAGNOSES_ICD table, which contains the clinical diagnoses and their corresponding ICD codes.\n","\n","MIMIC-IV Dataset: The MIMIC4Dataset object is initialized, pointing to the root directory of the MIMIC-IV Clinical dataset.\n","\n","Data Collection: The dataset is loaded, specifically the diagnoses data, which includes patient IDs and their diagnoses in ICD 9 / 10 format."],"metadata":{"id":"LHHmTskQsnOC"}},{"cell_type":"code","source":["from pyhealth.datasets import MIMIC4Dataset\n","import urllib.request\n","\n","mimic_dataset = MIMIC4Dataset(\n","    ehr_root=\"/content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/\", # Adapt and point this to where you have MIMICIV downloaded.\n","    ehr_tables=[\"DIAGNOSES_ICD\"],\n","    ehr_config_path=\"/content/drive/MyDrive/PyHealth/pyhealth/datasets/configs/mimic4_ehr.yaml\",\n","    dev=False\n",")\n","\n","mimic4 = mimic_dataset.global_event_df.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Of4lQrLp3Pze","executionInfo":{"status":"ok","timestamp":1746655536259,"user_tz":240,"elapsed":13630,"user":{"displayName":"Swaroop Potdar","userId":"00045263918087141429"}},"outputId":"c86861fc-0494-4582-a0b6-2719f8e5a303","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Memory usage Starting MIMIC4Dataset init: 4159.5 MB\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.mimic4:Memory usage Starting MIMIC4Dataset init: 4159.5 MB\n"]},{"output_type":"stream","name":"stdout","text":["Initializing MIMIC4EHRDataset with tables: ['DIAGNOSES_ICD'] (dev mode: False)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.mimic4:Initializing MIMIC4EHRDataset with tables: ['DIAGNOSES_ICD'] (dev mode: False)\n"]},{"output_type":"stream","name":"stdout","text":["Memory usage Before initializing mimic4_ehr: 4159.5 MB\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.mimic4:Memory usage Before initializing mimic4_ehr: 4159.5 MB\n"]},{"output_type":"stream","name":"stdout","text":["Initializing mimic4_ehr dataset from /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/ (dev mode: False)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.base_dataset:Initializing mimic4_ehr dataset from /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/ (dev mode: False)\n"]},{"output_type":"stream","name":"stdout","text":["Scanning table: diagnoses_icd from /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/hosp/diagnoses_icd.csv.gz\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.base_dataset:Scanning table: diagnoses_icd from /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/hosp/diagnoses_icd.csv.gz\n"]},{"output_type":"stream","name":"stdout","text":["Joining with table: /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/hosp/admissions.csv.gz\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.base_dataset:Joining with table: /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/hosp/admissions.csv.gz\n"]},{"output_type":"stream","name":"stdout","text":["Scanning table: patients from /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/hosp/patients.csv.gz\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.base_dataset:Scanning table: patients from /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/hosp/patients.csv.gz\n"]},{"output_type":"stream","name":"stdout","text":["Scanning table: admissions from /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/hosp/admissions.csv.gz\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.base_dataset:Scanning table: admissions from /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/hosp/admissions.csv.gz\n"]},{"output_type":"stream","name":"stdout","text":["Scanning table: icustays from /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/icu/icustays.csv.gz\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.base_dataset:Scanning table: icustays from /content/drive/MyDrive/MIMICIV/physionet.org/files/mimiciv/3.1/icu/icustays.csv.gz\n"]},{"output_type":"stream","name":"stdout","text":["Memory usage After initializing mimic4_ehr: 4160.3 MB\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.mimic4:Memory usage After initializing mimic4_ehr: 4160.3 MB\n"]},{"output_type":"stream","name":"stdout","text":["Memory usage After EHR dataset initialization: 4160.3 MB\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.mimic4:Memory usage After EHR dataset initialization: 4160.3 MB\n"]},{"output_type":"stream","name":"stdout","text":["Memory usage Before combining data: 4160.3 MB\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.mimic4:Memory usage Before combining data: 4160.3 MB\n"]},{"output_type":"stream","name":"stdout","text":["Combining data from ehr dataset\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.mimic4:Combining data from ehr dataset\n"]},{"output_type":"stream","name":"stdout","text":["Creating combined dataframe\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.mimic4:Creating combined dataframe\n"]},{"output_type":"stream","name":"stdout","text":["Memory usage After combining data: 4160.3 MB\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.mimic4:Memory usage After combining data: 4160.3 MB\n"]},{"output_type":"stream","name":"stdout","text":["Memory usage Completed MIMIC4Dataset init: 4160.3 MB\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pyhealth.datasets.mimic4:Memory usage Completed MIMIC4Dataset init: 4160.3 MB\n"]}]},{"cell_type":"markdown","source":["### Filter and Clean the Clinical Data\n","\n","Next, we filter the dataset to remove null diagnoses and columns with all null values.\n","\n","Filtering: The data is filtered to exclude rows where the diagnosis ICD code is null.\n","\n","Column Cleanup: We also drop columns where all values are null."],"metadata":{"id":"YVJrqO32tpCN"}},{"cell_type":"code","source":["import polars as pl\n","\n","mimic4_filtered = mimic4.filter(pl.col(\"diagnoses_icd/icd_code\") != \"null\")\n","mimic4_filtered = mimic4_filtered[[s.name for s in mimic4_filtered if not (s.null_count() == mimic4_filtered.height)]]"],"metadata":{"id":"Rba2qq0wLmAX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load MIMIC-IV Waveform Database Records\n","Now, we load the MIMIC-IV waveform database (WaveDB) records. These records represent the paths to the waveform files.\n","\n","Get WaveDB Records: We fetch the record paths for waveform files hosted on PhysioNet.\n","\n","Clean HTML: Using regex, we clean up the HTML tags from the downloaded content.\n","\n","Extract Record IDs: The record IDs (which are part of the path) are extracted using a regex pattern. We then build a DataFrame with the record_id and corresponding download_url."],"metadata":{"id":"Pq2Vt6K-t2pa"}},{"cell_type":"code","source":["base_url = \"https://physionet.org/files/mimic4wdb/0.1.0/\"\n","\n","url = \"https://physionet.org/content/mimic4wdb/0.1.0/RECORDS\"\n","\n","response = requests.get(url)\n","response.raise_for_status()\n","cleaned_content = re.sub(r'<pre.*?>|</pre>|<code.*?>|</code>', '', response.text)\n","\n","lines = cleaned_content.strip().splitlines()\n","\n","records = [\n","    {\n","        \"record_id\": re.search(r'/p(\\d{8})/', line).group(1),\n","        \"download_url\": base_url + line.strip('/')\n","    }\n","    for line in lines\n","    if re.search(r'/p\\d{8}/', line)\n","]\n","\n","wave_records = pd.DataFrame(records)\n","record_ids = wave_records['record_id'].tolist()"],"metadata":{"id":"3dBz7W8EOY_l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Merge Clinical Data with Waveform Data\n","Now, we filter the MIMIC-IV clinical dataset (mimic4_filtered) by matching patient IDs from the waveform dataset (wave_records).\n","\n","We filter the mimic4_filtered dataset to include only those rows where the patient_id is present in the waveform records. This ensures that we only work with patients who have corresponding waveform data available."],"metadata":{"id":"CG1rVJsCuLEj"}},{"cell_type":"code","source":["mimic4_match = mimic4_filtered.filter(pl.col(\"patient_id\").is_in(record_ids))\n","result = mimic4_match"],"metadata":{"id":"ppD2uD7iO4jd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load ICD-9 and ICD-10 Diagnosis Labels\n","To get more human-readable names for the diagnoses, we load and clean the ICD-9 and ICD-10 code mappings from bioontology.org\n"],"metadata":{"id":"lQcODy0kufCo"}},{"cell_type":"code","source":["import pandas as pd\n","\n","ics9 = pd.read_csv(\"https://data.bioontology.org/ontologies/ICD9CM/download?apikey=8b5b7825-538d-40e0-9e9e-5ab9274a9aeb&download_format=csv\",compression='gzip',header=0,sep=',',quotechar='\"')\n","raw_data = ics9\n","raw_data['flat_code'] = raw_data['Class ID'].apply(lambda x: x.split('/')[-1].replace('.', ''))\n","ics9_data = raw_data[['flat_code','Preferred Label']]\n","\n","ics10 = pd.read_csv(\"https://data.bioontology.org/ontologies/ICD10CM/download?apikey=8b5b7825-538d-40e0-9e9e-5ab9274a9aeb&download_format=csv\", compression='gzip', header=0, sep=',', quotechar='\"')\n","raw_data = ics10\n","raw_data['flat_code'] = raw_data['Class ID'].apply(lambda x: x.split('/')[-1].replace('.', ''))\n","ics10_data = raw_data[['flat_code','Preferred Label']]\n","\n","all_ics = pd.concat([ics9_data,ics10_data])"],"metadata":{"id":"RdAqD-iEccTy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Merge Diagnosis Data with Waveform Data\n","Now, we merge the filtered MIMIC-IV clinical data (mimic4_match) with the diagnosis labels (all_ics), allowing us to add the human-readable diagnosis names to our dataset.\n","\n","Merging: We perform a left join between the filtered MIMIC-IV data and the ICD codes to add the diagnosis labels.\n","\n","Missing Values: We fill any missing values with \"NA\" for clarity."],"metadata":{"id":"3oJrr_gcu5a6"}},{"cell_type":"code","source":["mimic_merged = pd.merge(result.to_pandas(), all_ics, left_on='diagnoses_icd/icd_code', right_on='flat_code', how='left')\n","mimic_merged.fillna(\"NA\",inplace=True)\n","mimic_merged"],"metadata":{"id":"R1HMWkt_xKqS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Search for Specific Diagnoses (e.g., Atrial Fibrillation)\n","\n","Finally, we can filter the merged dataset to find patients diagnosed with Atrial Fibrillation, or any other condition you might choose. These would be our positive class."],"metadata":{"id":"DU3aKBLtvQEX"}},{"cell_type":"code","source":["target_diagnosis = \"atrial\" # Adapt this to search for your specific target condition\n","positive_patients = mimic_merged[mimic_merged['Preferred Label'].str.contains(target_diagnosis,case=False)]\n"],"metadata":{"id":"j3-wgpi9fbRs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Select Control Group (Negative Class)\n","\n","Finally we filter our control group, where the patients are negative for the target condition and patient ids do not overlap with the positive patients."],"metadata":{"id":"SOaabFutxK62"}},{"cell_type":"code","source":["positive_patient_ids = positive_patients['patient_id'].tolist()\n","\n","negative_patients = mimic_merged[~mimic_merged['patient_id'].isin(positive_patient_ids)]"],"metadata":{"id":"21ACl4WBxKmE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Download Files for Positive and Negative Controls\n","\n","Finally we only download the required files for our controls sets. These can then be read through WFDB and normalized or tokenized or structured as per the needs of your machine learning models."],"metadata":{"id":"uNQ0RKjB_Ez7"}},{"cell_type":"code","source":["import random\n","import os\n","import subprocess\n","\n","positive_patient_ids = list(set(chk['patient_id'].tolist()))  # Unique positive patient IDs\n","negative_patient_ids = list(set(negative_patients['patient_id'].tolist()))  # Unique negative patient IDs\n","\n","target_num = 1 # Adapt this to match your required dataset size set to 1 for demo.\n","\n","# Select target_num random positive patients (those with Target Condition)\n","selected_positive_ids = random.sample(positive_patient_ids, 1)\n","\n","# Select target_num random negative patients (those without Target Condition)\n","selected_negative_ids = random.sample(negative_patient_ids, 1)\n","\n","selected_patient_ids = selected_positive_ids + selected_negative_ids\n","\n","selected_wave_records = wave_records[wave_records['record_id'].isin(selected_patient_ids)]\n","\n","# Create a directory to store the downloaded waveform data\n","download_dir = \"/content/drive/MyDrive/waveform_data/\"\n","os.makedirs(download_dir, exist_ok=True)\n","\n","# Download the waveform data for the selected patients\n","for index, row in selected_wave_records.iterrows():\n","    record_id = row['record_id']\n","    download_url = row['download_url']\n","\n","    # Determine if the patient is positive or negative\n","    if record_id in selected_positive_ids:\n","        target_subdir = 'positive'\n","    else:\n","        target_subdir = 'negative'\n","\n","    # Prepare the output directory for saving the files (separate for positive and negative)\n","    output_dir = os.path.join(download_dir, target_subdir, f\"p{record_id}\")\n","    os.makedirs(output_dir, exist_ok=True)  # Create sub-directory for each patient\n","\n","    # Dynamically build the patient-specific download URL\n","    patient_directory_url = download_url.rstrip('/') + \"/\"\n","\n","    print(f\"Attempting to download files from: {patient_directory_url}\")\n","\n","    # Use wget to recursively download all files from the patient's subdirectory\n","    subprocess.run([\n","        \"wget\",\n","        \"-r\",         # Recursive download\n","        \"-N\",         # Only download newer files\n","        \"-c\",         # Continue downloading where it left off\n","        \"-np\",        # No parent (don't go to parent directories)\n","        \"-nH\",        # Disable generation of host directories\n","        \"--cut-dirs=3\", # Remove unnecessary parts of the URL structure\n","        \"-P\", output_dir,  # Set the output directory for downloaded files\n","        patient_directory_url  # The URL to the patient's specific subdirectory\n","    ])\n","\n","    print(f\"Downloaded all files to: {output_dir}\")\n","\n","print(\"Download complete for selected patients.\")"],"metadata":{"id":"gPfhDC2R0Fxy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Optional (Loading Data with WFDB)\n","\n","In the next example we will demonstrate how to use WFDB to read into these files, select the leads of interest and assign appropriate ground truth labels."],"metadata":{"id":"-vK0jW9PCNmK"}}]}